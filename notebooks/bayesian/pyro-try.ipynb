{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Pyro\n",
    "\n",
    "[Pyro](https://pyro.ai/) is an open-source Probabilistic Programming library, originally developed by Uber. It uses PyTorch on the backend.\n",
    "\n",
    "## Quick introduction to PyTorch\n",
    "\n",
    "This section is mostly a recreation of PyTorch's [own getting started documentation](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n",
    "\n",
    "### Tensors\n",
    "\n",
    "To start off with terminology, PyTorch **tensors** can be thought of as GPU-accelerated ndarrays (from NumPy). For example, we can get a $5 \\times 3$ random tensor as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5290, 0.9945, 0.8214],\n",
      "        [0.5325, 0.6967, 0.5570],\n",
      "        [0.2706, 0.3105, 0.7093],\n",
      "        [0.2892, 0.3908, 0.3652],\n",
      "        [0.7669, 0.1806, 0.8546]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.rand(5, 3))\n",
    "print(torch.zeros(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify the datatype using the `dtype` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interoperability with NumPy is a major feature. For example, we can transform a NumPy ndarray into a tensor and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "tensor([1, 1, 1])\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_array = np.ones(3, dtype=np.long)\n",
    "pytorch_tensor = torch.from_numpy(numpy_array)\n",
    "print(numpy_array)\n",
    "print(pytorch_tensor)\n",
    "print(pytorch_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory is shared among both, so in-place operations are reflected in both variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "np.add(numpy_array, 2, out=numpy_array)\n",
    "print(pytorch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important characteristic of tensors is their ability to track the operations on themselves, if `requires_grad` is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "grad_tensor_1 = torch.ones(2, 2, requires_grad=True)\n",
    "print(grad_tensor_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x7efd60b318b0>\n"
     ]
    }
   ],
   "source": [
    "grad_tensor_2 = grad_tensor_1 + 2\n",
    "print(grad_tensor_2)\n",
    "print(grad_tensor_2.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "grad_tensor_3 = grad_tensor_2 * grad_tensor_2 * 3\n",
    "out = grad_tensor_3.mean()\n",
    "print(grad_tensor_3)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a backpropagation on the `out` variable, and get the matrix with the `grad` parameter of the first tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(grad_tensor_1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also mode tensors into the GPU and back using `.to`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='cuda:0')\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='cuda:0', grad_fn=<CopyBackwards>)\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]], dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_tensor = torch.ones_like(grad_tensor_1, device=device)\n",
    "    print(gpu_tensor)\n",
    "    gpu_tensor_using_to = grad_tensor_1.to(device)\n",
    "    print(gpu_tensor_using_to)\n",
    "    sum_gpu_tensors = gpu_tensor + gpu_tensor_using_to\n",
    "    print(sum_gpu_tensors)\n",
    "    print(sum_gpu_tensors.to(\"cpu\", dtype=torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions\n",
    "\n",
    "The [`torch.distributions`](https://pytorch.org/docs/master/distributions.html) package is composed of parameterizable probability distributions and sampling functions, and is designed like the TensorFlow Distributions package. The abstract base class of these is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.distributions.distribution.Distribution"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can, for example, use the Bernoulli distribution as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 0.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [1., 0., 1., 0., 1.],\n",
       "        [1., 1., 0., 1., 1.],\n",
       "        [1., 1., 0., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = torch.distributions.Bernoulli(0.7)\n",
    "dist.sample(sample_shape=[10, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pyro ideas\n",
    "\n",
    "This section is a recreation of the [Pyro tutorials documentation](http://pyro.ai/examples/index.html).\n",
    "\n",
    "A **stochastic function** (or **models** in Pyro's terminology) is the basic unit of probabilistic programs. Concretely, they can be any Python callable.\n",
    "\n",
    "**Primitive stochastic functions** (or **distributions**) are stochastic functions for which we can explicitly compute the probability of the outputs, given the inputs. Pyro has the thin wrapper `pyro.distributions` for PyTorch's distributions package, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3905, -0.8152, -0.3204,  0.7377, -1.7534])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyro\n",
    "\n",
    "pyro.set_rng_seed(101)\n",
    "normal = pyro.distributions.Normal(0, 1)\n",
    "normal.sample(sample_shape=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
